{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73b22d2a",
   "metadata": {},
   "source": [
    "## **Hypothesis Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0834297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikit_posthocs as sp\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,.4f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3035f75",
   "metadata": {},
   "source": [
    "## Normality Test Function\n",
    "\n",
    "This Python function, `check_normality(data)`, is designed to assess whether a given dataset is **normally distributed**. It utilizes the **Shapiro-Wilk Test**, a common statistical test for normality.\n",
    "\n",
    "### How it Works\n",
    "\n",
    "1.  **Shapiro-Wilk Test Execution**:\n",
    "    The function calls `stats.shapiro(data)` from the `scipy.stats` module. This function returns two key values:\n",
    "    * `test_stat_normality`: The test statistic for the Shapiro-Wilk test.\n",
    "    * `p_value_normality`: The **p-value** associated with the test.\n",
    "\n",
    "2.  **P-value Interpretation**:\n",
    "    The p-value is crucial for determining normality. The function prints the calculated p-value, formatted to four decimal places.\n",
    "\n",
    "3.  **Hypothesis Testing**:\n",
    "    The core of the normality check lies in comparing the p-value to a significance level (commonly $\\alpha = 0.05$).\n",
    "\n",
    "    * **Null Hypothesis ($H_0$)**: The data is normally distributed.\n",
    "    * **Alternative Hypothesis ($H_1$)**: The data is *not* normally distributed.\n",
    "\n",
    "    * If **$p$-value < $0.05$**: We **reject the null hypothesis**. This means there is sufficient evidence to conclude that the data is **not normally distributed**.\n",
    "    * If **$p$-value $\\ge 0.05$**: We **fail to reject the null hypothesis**. This suggests there isn't enough evidence to claim the data is not normally distributed, implying it **can be considered normally distributed**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a762af8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_normality(data):\n",
    "    test_stat_normality, p_value_normality=stats.shapiro(data)\n",
    "    print(\"p value:%.4f\" % p_value_normality)\n",
    "    if p_value_normality <0.05:\n",
    "        print(\"Reject null hypothesis >> The data is not normally distributed\")\n",
    "    else:\n",
    "        print(\"Fail to reject null hypothesis >> The data is normally distributed\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d872ebb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_variance_homogeneity(group1, group2):\n",
    "    test_stat_var, p_value_var= stats.levene(group1,group2)\n",
    "    print(\"p value:%.4f\" % p_value_var)\n",
    "    if p_value_var <0.05:\n",
    "        print(\"Reject null hypothesis >> The variances of the samples are different.\")\n",
    "    else:\n",
    "        print(\"Fail to reject null hypothesis >> The variances of the samples are same.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4854f953",
   "metadata": {},
   "source": [
    "## Variance Homogeneity Test Function\n",
    "\n",
    "This Python function, `check_variance_homogeneity(group1, group2)`, is designed to assess whether the **variances of two or more independent samples are equal**. This property is known as **homogeneity of variances** or **homoscedasticity**. It utilizes **Levene's Test**, a robust statistical test for this purpose.\n",
    "\n",
    "### Why is this important?\n",
    "\n",
    "Many statistical tests (e.g., independent samples t-test, ANOVA) assume that the variances of the groups being compared are equal. If this assumption is violated, the results of those tests might be unreliable.\n",
    "\n",
    "### How it Works\n",
    "\n",
    "1.  **Levene's Test Execution**:\n",
    "    The function calls `stats.levene(group1, group2)` from the `scipy.stats` module. This function takes two (or more) sample arrays as input and returns:\n",
    "    * `test_stat_var`: The test statistic for Levene's test.\n",
    "    * `p_value_var`: The **p-value** associated with the test.\n",
    "\n",
    "2.  **P-value Interpretation**:\n",
    "    The p-value is crucial for determining variance homogeneity. The function prints the calculated p-value, formatted to four decimal places.\n",
    "\n",
    "3.  **Hypothesis Testing**:\n",
    "    The core of the variance homogeneity check lies in comparing the p-value to a significance level (commonly $\\alpha = 0.05$).\n",
    "\n",
    "    * **Null Hypothesis ($H_0$)**: The variances of the samples are equal (homogeneous).\n",
    "    * **Alternative Hypothesis ($H_1$)**: The variances of the samples are different (heterogeneous).\n",
    "\n",
    "    * If **$p$-value < $0.05$**: We **reject the null hypothesis**. This means there is sufficient evidence to conclude that the variances of the samples are **different**.\n",
    "    * If **$p$-value $\\ge 0.05$**: We **fail to reject the null hypothesis**. This suggests there isn't enough evidence to claim the variances are different, implying they **can be considered the same**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7770b9",
   "metadata": {},
   "source": [
    "## **Question 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793f55be",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Investigating Academic Performance: Synchronous vs. Asynchronous Learning\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "A university professor wants to determine if students who attend live online sessions (synchronous learning) and actively participate perform better academically than students who watch recorded lectures later (asynchronous learning). The average semester grades for both groups have been collected.\n",
    "\n",
    "### Data\n",
    "\n",
    "* **Synchronous Group Grades:**\n",
    "    `[94. , 84.9, 82.6, 69.5, 80.1, 79.6, 81.4, 77.8, 81.7, 78.8, 73.2, 87.9, 87.9, 93.5, 82.3, 79.3, 78.3, 71.6, 88.6, 74.6, 74.1, 80.6]`\n",
    "* **Asynchronous Group Grades:**\n",
    "    `[77.1, 71.7, 91. , 72.2, 74.8, 85.1, 67.6, 69.9, 75.3, 71.7, 65.7, 72.6, 71.5, 78.2]`\n",
    "\n",
    "**Conduct the hypothesis testing to check whether the professor's belief is statistically significant by using a 0.05 significance level to evaluate the null and alternative hypotheses. Before doing hypothesis testing, check the related assumptions. Comment on the results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7594d946",
   "metadata": {},
   "source": [
    "## **Assumptions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46739054",
   "metadata": {},
   "source": [
    "1. Observations in each sample are independent and identically distributed (iid).\n",
    "2. Observations in each sample are normally distributed.\n",
    "3. Observations in each sample have the same variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b28f499",
   "metadata": {},
   "outputs": [],
   "source": [
    "sync = np.array([94. , 84.9, 82.6, 69.5, 80.1, 79.6, 81.4, 77.8, 81.7, 78.8, 73.2,\n",
    "       87.9, 87.9, 93.5, 82.3, 79.3, 78.3, 71.6, 88.6, 74.6, 74.1, 80.6])\n",
    "asyncr =np.array([77.1, 71.7, 91. , 72.2, 74.8, 85.1, 67.6, 69.9, 75.3, 71.7, 65.7, 72.6, 71.5, 78.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f6e3a0",
   "metadata": {},
   "source": [
    "*   $H_0$: The data is normally distributed.\n",
    "*   $H_A$: The data is not normally distributed.\n",
    "\n",
    "Assume that alpha=0.05 If p-value is >0.05, it can be said that data is normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfc46af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.6556\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n",
      "p value:0.0803\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n"
     ]
    }
   ],
   "source": [
    "check_normality(sync)\n",
    "check_normality(asyncr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fe95ec",
   "metadata": {},
   "source": [
    "*   $H_0$: The variances of the samples are same.\n",
    "*   $H_A$: The variances of the samples are different.\n",
    "\n",
    "It tests the null hypothesis that the population variances are equal (called homogeneity of variance or homoscedasticity). If the resulting p-value of Levene's test is less than some significance level (typically 0.05), the obtained differences in sample variances are unlikely to have occurred based on random sampling from a population with equal variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c48a054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.8149\n",
      "Fail to reject null hypothesis >> The variances of the samples are same.\n"
     ]
    }
   ],
   "source": [
    "check_variance_homogeneity(sync, asyncr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7392f958",
   "metadata": {},
   "source": [
    "$H_{0}$: $\\mu_{s}<= \\mu_{a}$     \n",
    "$H_{1}$: $\\mu_{s}>  \\mu_{a}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89367508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- One-Tailed T-Test Results (using `alternative` parameter) ---\n",
      "Test Statistic: 2.8415\n",
      "P-value (one-tailed): 0.0038\n",
      "Reject the null hypothesis (p < 0.05)\n",
      "Conclusion: The average grades of synchronous students are significantly higher than those of asynchronous students.\n"
     ]
    }
   ],
   "source": [
    "# For a one-tailed test, we use `alternative='greater'`\n",
    "test_statistic, p_value = stats.ttest_ind(\n",
    "    sync, asyncr,\n",
    "    equal_var=True, # Should be adjusted based on normality and variance homogeneity\n",
    "    alternative='greater' # We are testing the hypothesis: Synchronous > Asynchronous\n",
    ")\n",
    "\n",
    "print(\"\\n--- One-Tailed T-Test Results (using `alternative` parameter) ---\")\n",
    "print(\"Test Statistic: %.4f\" % test_statistic)\n",
    "print(\"P-value (one-tailed): %.4f\" % p_value)\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(f\"Reject the null hypothesis (p < {alpha})\")\n",
    "    print(\"Conclusion: The average grades of synchronous students are significantly higher than those of asynchronous students.\")\n",
    "else:\n",
    "    print(f\"Fail to reject the null hypothesis (p >= {alpha})\")\n",
    "    print(\"Conclusion: There is no significant statistical evidence that the average grades of synchronous students are higher than those of asynchronous students.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90c7b1e",
   "metadata": {},
   "source": [
    "## Q2.\n",
    "A pediatrician wants to see the effect of formula consumption on the average monthly weight gain (in gr) of babies. For this reason, she collected  data from three different groups. The first group is exclusively breastfed children(receives only breast milk), the second group is children who are fed with only formula and the last group is both formula and breastfed children. These data are as below \n",
    "\n",
    "\n",
    "only_breast=[794.1, 716.9, 993. , 724.7, 760.9, 908.2, 659.3 , 690.8, 768.7,\n",
    "       717.3 , 630.7, 729.5, 714.1, 810.3, 583.5, 679.9, 865.1]      \n",
    "   \n",
    "only_formula=[ 898.8,  881.2,  940.2,  966.2,  957.5, 1061.7, 1046.2,  980.4,\n",
    "        895.6,  919.7, 1074.1,  952.5,  796.3,  859.6,  871.1 , 1047.5,\n",
    "        919.1 , 1160.5,  996.9]     \n",
    "        \n",
    "both=[976.4, 656.4, 861.2, 706.8, 718.5, 717.1, 759.8, 894.6, 867.6,\n",
    "       805.6, 765.4, 800.3, 789.9, 875.3, 740. , 799.4, 790.3, 795.2 ,\n",
    "       823.6, 818.7, 926.8, 791.7, 948.3]  \n",
    "**According to this information, conduct the hypothesis testing to check whether there is a difference between the average monthly gain of these three groups by using a 0.05 significance level. If there is a significant difference, perform further analysis to find what caused the difference.  Before doing hypothesis testing, check the related assumptions. Comment on the results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d99327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_breast=np.array([794.1, 716.9, 993. , 724.7, 760.9, 908.2, 659.3 , 690.8, 768.7,\n",
    "       717.3 , 630.7, 729.5, 714.1, 810.3, 583.5, 679.9, 865.1])\n",
    "\n",
    "only_formula=np.array([ 898.8,  881.2,  940.2,  966.2,  957.5, 1061.7, 1046.2,  980.4,\n",
    "        895.6,  919.7, 1074.1,  952.5,  796.3,  859.6,  871.1 , 1047.5,\n",
    "        919.1 , 1160.5,  996.9])\n",
    "\n",
    "both=np.array([976.4, 656.4, 861.2, 706.8, 718.5, 717.1, 759.8, 894.6, 867.6,\n",
    "       805.6, 765.4, 800.3, 789.9, 875.3, 740. , 799.4, 790.3, 795.2 ,\n",
    "       823.6, 818.7, 926.8, 791.7, 948.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afed789",
   "metadata": {},
   "source": [
    "$ H_{0} $: The data is normally distributed.  \n",
    "$ H_{1} $: The data is not normally distributed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63d6ba8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.4694\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n",
      "p value:0.8879\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n",
      "p value:0.7973\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n"
     ]
    }
   ],
   "source": [
    "check_normality(only_breast)\n",
    "check_normality(only_formula)\n",
    "check_normality(both)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1492ded",
   "metadata": {},
   "source": [
    "$H_{0}$: The variances of the samples are the same.  \n",
    "$H_{1}$: The variances of the samples are different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bea1fbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.7673\n",
      "Fail to reject null hypothesis >> The variances of the samples are same.\n"
     ]
    }
   ],
   "source": [
    "stat, pvalue_levene= stats.levene(only_breast,only_formula,both)\n",
    "\n",
    "print(\"p value:%.4f\" % pvalue_levene)\n",
    "if pvalue_levene <0.05:\n",
    "    print(\"Reject null hypothesis >> The variances of the samples are different.\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis >> The variances of the samples are same.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02ae854",
   "metadata": {},
   "source": [
    "$H_{0}$: $\\mu_{1}= \\mu_{2}= \\mu_{3} $ **or** The mean of the samples is the same.      \n",
    "$H_{1}$: At least one of them is different.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d183b972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.000000\n",
      "Reject null hypothesis\n"
     ]
    }
   ],
   "source": [
    "F, p_value = stats.f_oneway(only_breast,only_formula,both)\n",
    "print(\"p value:%.6f\" % p_value)\n",
    "if p_value <0.05:\n",
    "    print(\"Reject null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37136500",
   "metadata": {},
   "source": [
    "**At this significance level, it can be concluded that at least one of the groups has a different average monthly weight gain.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6794d8",
   "metadata": {},
   "source": [
    "### post hoc // pairwise comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e3da3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nihat\\AppData\\Local\\Temp\\ipykernel_32188\\3991130949.py:10: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  posthoc_df.style.applymap(lambda x: \"background-color:violet\" if x<0.05 else \"background-color: lightgreen\", subset=group_names).format(\"{:.4f}\").set_caption(\"Pairwise T-test Results with Bonferroni Correction\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8faba_row0_col0, #T_8faba_row0_col2, #T_8faba_row1_col1, #T_8faba_row2_col0, #T_8faba_row2_col2 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "#T_8faba_row0_col1, #T_8faba_row1_col0, #T_8faba_row1_col2, #T_8faba_row2_col1 {\n",
       "  background-color: violet;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8faba\">\n",
       "  <caption>Pairwise T-test Results with Bonferroni Correction</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8faba_level0_col0\" class=\"col_heading level0 col0\" >only breast</th>\n",
       "      <th id=\"T_8faba_level0_col1\" class=\"col_heading level0 col1\" >only formula</th>\n",
       "      <th id=\"T_8faba_level0_col2\" class=\"col_heading level0 col2\" >both</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8faba_level0_row0\" class=\"row_heading level0 row0\" >only breast</th>\n",
       "      <td id=\"T_8faba_row0_col0\" class=\"data row0 col0\" >1.0000</td>\n",
       "      <td id=\"T_8faba_row0_col1\" class=\"data row0 col1\" >0.0000</td>\n",
       "      <td id=\"T_8faba_row0_col2\" class=\"data row0 col2\" >0.1295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8faba_level0_row1\" class=\"row_heading level0 row1\" >only formula</th>\n",
       "      <td id=\"T_8faba_row1_col0\" class=\"data row1 col0\" >0.0000</td>\n",
       "      <td id=\"T_8faba_row1_col1\" class=\"data row1 col1\" >1.0000</td>\n",
       "      <td id=\"T_8faba_row1_col2\" class=\"data row1 col2\" >0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8faba_level0_row2\" class=\"row_heading level0 row2\" >both</th>\n",
       "      <td id=\"T_8faba_row2_col0\" class=\"data row2 col0\" >0.1295</td>\n",
       "      <td id=\"T_8faba_row2_col1\" class=\"data row2 col1\" >0.0000</td>\n",
       "      <td id=\"T_8faba_row2_col2\" class=\"data row2 col2\" >1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x24930b11d00>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install scikit-posthocs\n",
    "# Pairwise T test for multiple comparisons of independent groups. May be used after a parametric ANOVA to do pairwise comparisons.\n",
    "\n",
    "import scikit_posthocs as sp\n",
    "posthoc_df= sp.posthoc_ttest([only_breast,only_formula,both], equal_var=True, p_adjust=\"bonferroni\")\n",
    "\n",
    "group_names= [\"only breast\", \"only formula\",\"both\"]\n",
    "posthoc_df.columns= group_names\n",
    "posthoc_df.index= group_names\n",
    "posthoc_df.style.applymap(lambda x: \"background-color:violet\" if x<0.05 else \"background-color: lightgreen\", subset=group_names).format(\"{:.4f}\").set_caption(\"Pairwise T-test Results with Bonferroni Correction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a34fd0",
   "metadata": {},
   "source": [
    "**At this significance level, it can be concluded that**\n",
    "- \"only breast\" is different than \"only formula\"\n",
    "- \"only formula\" is different than both \"only breast\" and \"both\"\n",
    "- \"both\" is different than \"only formula\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b11f0efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0432</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       1      2      3\n",
       "1 1.0000 0.0000 0.0432\n",
       "2 0.0000 1.0000 0.0000\n",
       "3 0.0432 0.0000 1.0000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.posthoc_ttest([only_breast,only_formula,both], equal_var=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9def3abc",
   "metadata": {},
   "source": [
    "-------\n",
    "## Q3.\n",
    "A human resource specialist working in a technology company is interested in the overwork time of different teams. To investigate whether there is a difference between overtime of the software development team and the test team, she selected 17 employees randomly in each of the two teams and recorded their weekly average overwork time in terms of an hour. The data is below.   \n",
    "\n",
    "test_team=[6.2,  7.1,  1.5,  2,3 ,  2,  1.5,  6.1,  2.4,  2.3, 12.4,  1.8,  5.3,  3.1, 9.4,  2.3, 4.1]    \n",
    "software_team=[2.3,  2.1,  1.4,  2.0, 8.7,  2.2,  3.1,  4.2,  3.6, 2.5,  3.1,  6.2, 12.1,  3.9,  2.2, 1.2 ,3.4]\n",
    "\n",
    "**According to this information, conduct the hypothesis testing to check whether there is a difference between the overwork time of two teams by using a 0.05 significance level. Before doing hypothesis testing, check the related assumptions. Comment on the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31a4d900",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_team=np.array([6.2,  7.1,  1.5,  2,3 ,  2,  1.5,  6.1,  2.4,  2.3, 12.4,  1.8,  5.3,  3.1, 9.4,  2.3, 4.1])\n",
    "developer_team=np.array([2.3,  2.1,  1.4,  2.0, 8.7,  2.2,  3.1,  4.2,  3.6, 2.5,  3.1,  6.2, 12.1,  3.9,  2.2, 1.2 ,3.4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39abffb1",
   "metadata": {},
   "source": [
    "$ H_{0} $: The data is normally distributed.  \n",
    "$ H_{1} $: The data is not normally distributed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27d1c502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.0046\n",
      "Reject null hypothesis >> The data is not normally distributed\n",
      "p value:0.0005\n",
      "Reject null hypothesis >> The data is not normally distributed\n"
     ]
    }
   ],
   "source": [
    "check_normality(test_team)\n",
    "check_normality(developer_team)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af857540",
   "metadata": {},
   "source": [
    "$H_{0}$: The variances of the samples are the same.  \n",
    "$H_{1}$: The variances of the samples are different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26ea6e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.5410\n",
      "Fail to reject null hypothesis >> The variances of the samples are same.\n"
     ]
    }
   ],
   "source": [
    "check_variance_homogeneity(test_team, developer_team)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1218f3a1",
   "metadata": {},
   "source": [
    "$H_{0}$: $\\mu_{1}= \\mu_{2}$  **or** $\\mu_{1}- \\mu_{2} = 0 $  **or** The mean of the samples are same.      \n",
    "$H_{1}$: $\\mu_{1} \\neq \\mu_{2}$  **or** $\\mu_{1}- \\mu_{2} \\neq 0 $  **or** The mean of the samples are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3812f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value:0.8226\n",
      "Fail to reject null hypothesis\n"
     ]
    }
   ],
   "source": [
    "ttest,pvalue = stats.mannwhitneyu(test_team,developer_team, alternative=\"two-sided\")\n",
    "print(\"p-value:%.4f\" % pvalue)\n",
    "if pvalue <0.05:\n",
    "    print(\"Reject null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c35780",
   "metadata": {},
   "source": [
    "At this significance level, it can be said that there is no statistically significant difference between the average overwork time of the two teams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60af672",
   "metadata": {},
   "source": [
    "--------\n",
    "## Q4.\n",
    "\n",
    "An e-commerce company regularly advertises on YouTube, Instagram, and Facebook for its campaigns. However, the new manager was curious about if there was any difference between the number of customers attracted by these platforms. Therefore, she started to use Adjust, an application that allows you to find out where your users come from. The daily numbers reported from Adjust for each platform are as below. \n",
    "\n",
    "youtube=[1913, 1879, 1939, 2146, 2040, 2127, 2122, 2156, 2036, 1974, 1956, 2146, 2151, 1943, 2125]\n",
    "       \n",
    "instagram = [2305., 2355., 2203., 2231., 2185., 2420., 2386., 2410., 2340., 2349., 2241., 2396., 2244., 2267., 2281.]     \n",
    "       \n",
    "facebook = [2133., 2522., 2124., 2551., 2293., 2367., 2460., 2311., 2178., 2113., 2048., 2443., 2265., 2095., 2528.]          \n",
    "\n",
    "**According to this information, conduct the hypothesis testing to check whether there is a difference between the average customer acquisition of these three platforms using a 0.05 significance level. If there is a significant difference, perform further analysis to find that caused the difference. Before doing hypothesis testing, check the related assumptions. Comment on the results.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "164f1042",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube=np.array([1913, 1879, 1939, 2146, 2040, 2127, 2122, 2156, 2036, 1974, 1956,\n",
    "       2146, 2151, 1943, 2125])\n",
    "       \n",
    "instagram =  np.array([2305., 2355., 2203., 2231., 2185., 2420., 2386., 2410., 2340.,\n",
    "       2349., 2241., 2396., 2244., 2267., 2281.])\n",
    "       \n",
    "facebook = np.array([2133., 2522., 2124., 2551., 2293., 2367., 2460., 2311., 2178.,\n",
    "       2113., 2048., 2443., 2265., 2095., 2528.]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a017130f",
   "metadata": {},
   "source": [
    "$H_{0}$: The data is normally distributed.  \n",
    "$H_{1}$: The data is not normally distributed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5bd2830a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.0285\n",
      "Reject null hypothesis >> The data is not normally distributed\n",
      "p value:0.4156\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n",
      "p value:0.1716\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n"
     ]
    }
   ],
   "source": [
    "check_normality(youtube)\n",
    "check_normality(instagram)\n",
    "check_normality(facebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37af1c92",
   "metadata": {},
   "source": [
    "$H_{0}$: The variances of the samples are the same.  \n",
    "$H_{1}$: The variances of the samples are different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42d0f881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.0012\n",
      "Reject null hypothesis >> The variances of the samples are different.\n"
     ]
    }
   ],
   "source": [
    "stat, pvalue_levene= stats.levene(youtube, instagram, facebook)\n",
    "\n",
    "print(\"p value:%.4f\" % pvalue_levene)\n",
    "if pvalue_levene <0.05:\n",
    "    print(\"Reject null hypothesis >> The variances of the samples are different.\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis >> The variances of the samples are same.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37398d9",
   "metadata": {},
   "source": [
    "$H_{0}$: $\\mu_{1}= \\mu_{2}= \\mu_{3} $ **or** The mean of the samples are same.      \n",
    "$H_{1}$: At least one of them is different.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f86948e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.000015\n",
      "Reject null hypothesis\n"
     ]
    }
   ],
   "source": [
    "F, p_value = stats.kruskal(youtube, instagram, facebook)\n",
    "print(\"p value:%.6f\" % p_value)\n",
    "if p_value <0.05:\n",
    "    print(\"Reject null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5430eb3c",
   "metadata": {},
   "source": [
    "At this significance level, at least one of the average customer acquisition number is different.   \n",
    "Note: Since, the data is not normal, nonparametric version of posthoc test is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cc5cc1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_20843_row0_col0, #T_20843_row1_col1, #T_20843_row1_col2, #T_20843_row2_col1, #T_20843_row2_col2 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "#T_20843_row0_col1, #T_20843_row0_col2, #T_20843_row1_col0, #T_20843_row2_col0 {\n",
       "  background-color: violet;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_20843\">\n",
       "  <caption>Pairwise Mann-Whitney U Test Results with Bonferroni Correction</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_20843_level0_col0\" class=\"col_heading level0 col0\" >youtube</th>\n",
       "      <th id=\"T_20843_level0_col1\" class=\"col_heading level0 col1\" >instagram</th>\n",
       "      <th id=\"T_20843_level0_col2\" class=\"col_heading level0 col2\" >facebook</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_20843_level0_row0\" class=\"row_heading level0 row0\" >youtube</th>\n",
       "      <td id=\"T_20843_row0_col0\" class=\"data row0 col0\" >1.0000</td>\n",
       "      <td id=\"T_20843_row0_col1\" class=\"data row0 col1\" >0.0000</td>\n",
       "      <td id=\"T_20843_row0_col2\" class=\"data row0 col2\" >0.0023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_20843_level0_row1\" class=\"row_heading level0 row1\" >instagram</th>\n",
       "      <td id=\"T_20843_row1_col0\" class=\"data row1 col0\" >0.0000</td>\n",
       "      <td id=\"T_20843_row1_col1\" class=\"data row1 col1\" >1.0000</td>\n",
       "      <td id=\"T_20843_row1_col2\" class=\"data row1 col2\" >1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_20843_level0_row2\" class=\"row_heading level0 row2\" >facebook</th>\n",
       "      <td id=\"T_20843_row2_col0\" class=\"data row2 col0\" >0.0023</td>\n",
       "      <td id=\"T_20843_row2_col1\" class=\"data row2 col1\" >1.0000</td>\n",
       "      <td id=\"T_20843_row2_col2\" class=\"data row2 col2\" >1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x24930eb37d0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posthoc_df = sp.posthoc_mannwhitney([youtube,instagram, facebook], p_adjust = 'bonferroni')\n",
    "group_names= [\"youtube\", \"instagram\",\"facebook\"]\n",
    "posthoc_df.columns= group_names\n",
    "posthoc_df.index= group_names\n",
    "posthoc_df.style.map(lambda x: \"background-color:violet\" if x<0.05 else \"background-color: lightgreen\", subset=group_names).format(\"{:.4f}\").set_caption(\"Pairwise Mann-Whitney U Test Results with Bonferroni Correction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1cb7af",
   "metadata": {},
   "source": [
    "The average number of customers coming from YouTube is different than the other (actually smaller than the others).\n",
    "\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da62986d",
   "metadata": {},
   "source": [
    "## Q5.\n",
    "\n",
    "The METU Health Center diagnosed eighteen students with high cholesterol in the previous semester. Healthcare personnel told these patients about the dangers of high cholesterol and prescribed a diet program. One month later, the patients came for control, and their cholesterol level was reexamined. Test whether there is a difference in the cholesterol levels of the patients.   \n",
    "\n",
    "**According to this information, conduct the hypothesis testing to check whether there is a decrease in the cholesterol levels of the patients after the diet by using a 0.05 significance level. Before doing hypothesis testing, check the related assumptions. Comment on the results**\n",
    "\n",
    "test_results_before_diet=[224, 235, 223, 253, 253, 224, 244, 225, 259, 220, 242, 240, 239, 229, 276, 254, 237, 227]  \n",
    "test_results_after_diet=[198, 195, 213, 190, 246, 206, 225, 199, 214, 210, 188, 205, 200, 220, 190, 199, 191, 218]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdec631",
   "metadata": {},
   "source": [
    "## Assumptions\n",
    "• The dependent variable must be continuous (interval/ratio)  \n",
    "• The observations are independent of one another  \n",
    "• The dependent variable should be approximately normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9966bfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_before_diet=np.array([224, 235, 223, 253, 253, 224, 244, 225, 259, 220, 242, 240, 239, 229, 276, 254, 237, 227])\n",
    "test_results_after_diet=np.array([198, 195, 213, 190, 246, 206, 225, 199, 214, 210, 188, 205, 200, 220, 190, 199, 191, 218])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b27294",
   "metadata": {},
   "source": [
    "$H_{0}$: The data is normally distributed.  \n",
    "$H_{1}$: The data is not normally distributed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7824961b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.1635\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n",
      "p value:0.1003\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n"
     ]
    }
   ],
   "source": [
    "check_normality(test_results_before_diet)\n",
    "check_normality(test_results_after_diet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76567757",
   "metadata": {},
   "source": [
    "$H_{0}$: $\\mu_{d}>= 0 $ **or** The true mean difference is equal to or bigger than zero.   \n",
    "$H_{1}$: $\\mu_{d}< 0 $ **or**  The true mean difference is smaller than zero.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f9339f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.000008 one tailed p value:0.000004\n",
      "Reject null hypothesis\n"
     ]
    }
   ],
   "source": [
    "test_stat, p_value_paired = stats.ttest_rel(test_results_before_diet,test_results_after_diet)\n",
    "print(\"p value:%.6f\" % p_value_paired , \"one tailed p value:%.6f\" %(p_value_paired/2))\n",
    "if p_value_paired <0.05:\n",
    "    print(\"Reject null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cfebda",
   "metadata": {},
   "source": [
    "At this significance level, there is enough evidence to conclude mean cholesterol level of patients has decreased after the diet.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0087c75",
   "metadata": {},
   "source": [
    "## Q6.\n",
    "A venture capitalist wanted to invest in a startup that provides data compression without any loss in quality, but there are two competitors: PiedPiper and EndFrame. Initially, she believed the performance of the EndFrame could be better but still wanted to test it before the investment. Then, she gave the same files to each company to compress and recorded their performance scores. The data is below.    \n",
    "    \n",
    "piedpiper=[4.57, 4.55, 5.47, 4.67, 5.41, 5.55, 5.53, 5.63, 3.86, 3.97, 5.44, 3.93, 5.31, 5.17, 4.39, 4.28, 5.25]     \n",
    "endframe = [4.27, 3.93, 4.01, 4.07, 3.87, 4.  , 4.  , 3.72, 4.16, 4.1 , 3.9 , 3.97, 4.08, 3.96, 3.96, 3.77, 4.09]\n",
    "\n",
    "\n",
    "**According to this information, conduct the related hypothesis testing by using a 0.05 significance level. Before doing hypothesis testing, check the related assumptions. Comment on the results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85491bd2",
   "metadata": {},
   "source": [
    "## Assumptions\n",
    "• The dependent variable must be continuous (interval/ratio)  \n",
    "• The observations are independent of one another  \n",
    "• The dependent variable should be approximately normally distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17c470e",
   "metadata": {},
   "source": [
    "$H_{0}$: The data is normally distributed.  \n",
    "$H_{1}$: The data is not normally distributed.   \n",
    "Assume that alpha=0.05 If p-value is >0.05, it can be said that data is normality distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5f292108",
   "metadata": {},
   "outputs": [],
   "source": [
    "piedpiper=np.array([4.57, 4.55, 5.47, 4.67, 5.41, 5.55, 5.53, 5.63, 3.86, 3.97, 5.44, 3.93, 5.31, 5.17, 4.39, 4.28, 5.25])\n",
    "endframe = np.array([4.27, 3.93, 4.01, 4.07, 3.87, 4.  , 4.  , 3.72, 4.16, 4.1 , 3.9 , 3.97, 4.08, 3.96, 3.96, 3.77, 4.09])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fd27a4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.0304\n",
      "Reject null hypothesis >> The data is not normally distributed\n",
      "p value:0.9587\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n"
     ]
    }
   ],
   "source": [
    "check_normality(piedpiper)\n",
    "check_normality(endframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d1bb09",
   "metadata": {},
   "source": [
    "$H_{0}$: $\\mu_{d} >= 0 $ **or** The true mean difference is equal to or bigger than zero.   \n",
    "$H_{1}$: $\\mu_{d} < 0 $ **or**  The true mean difference is smaller than zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dfd5fd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.0001\n",
      "Reject null hypothesis >> The variances of the samples are different.\n"
     ]
    }
   ],
   "source": [
    "stat, pvalue_levene= stats.levene(piedpiper, endframe)\n",
    "print(\"p value:%.4f\" % pvalue_levene)\n",
    "if pvalue_levene <0.05:\n",
    "    print(\"Reject null hypothesis >> The variances of the samples are different.\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis >> The variances of the samples are same.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7c890a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value:0.000214 >> one_tailed_pval:0.000107\n",
      "one sided pvalue:0.000107\n",
      "Reject null hypothesis\n"
     ]
    }
   ],
   "source": [
    "test,pvalue = stats.wilcoxon(endframe,piedpiper) ##alternative default two sided\n",
    "print(\"p-value:%.6f\" %pvalue, \">> one_tailed_pval:%.6f\" %(pvalue/2))\n",
    "\n",
    "test,one_sided_pvalue = stats.wilcoxon(endframe,piedpiper, alternative=\"less\")\n",
    "print(\"one sided pvalue:%.6f\" %(one_sided_pvalue))\n",
    "if pvalue <0.05:\n",
    "    print(\"Reject null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to recejt null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0a48fd",
   "metadata": {},
   "source": [
    "Reject $H_{0}$ >> At this significance level, there is enough evidence to conclude that the performance the PiedPaper is better than the EndFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec80098",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Q7.\n",
    "\n",
    "A researcher was curious about whether there is a difference between the methodology she developed, C, and baseline methods A and B in terms of performance. Therefore, she decided to design different experiments and recorded the achieved accuracy by each method. The below table shows the achieved accuracy on test sets by each method. Please note that the same train and test sets were used for each method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb9d726",
   "metadata": {},
   "source": [
    "| Experiment |   A  |   B  |   C  |\n",
    "|:----------:|:----:|:----:|:----:|\n",
    "|     E1     | 89.8 | 90.0 | 91.5 |\n",
    "|     E2     | 89.9 | 90.1 | 90.7 |\n",
    "|     E3     | 88.6 | 88.8 | 90.3 |\n",
    "|     E4     | 88.7 | 88.9 | 90.4 |\n",
    "|     E5     | 89.6 | 89.9 | 90.2 |\n",
    "|     E6     | 89.7 | 90.0 | 90.3 |\n",
    "|     E7     | 89.2 | 89.0 | 90.2 |\n",
    "|     E8     | 89.3 | 89.2 | 90.3 | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3f7835",
   "metadata": {},
   "source": [
    "**According to this information, conduct the hypothesis testing to check whether there is a difference between the performance of the methods by using a 0.05 significance level. If there is a significant difference, perform further analysis to find which one caused the difference. Before doing hypothesis testing, check the related assumptions. Comment on the results.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d460b2",
   "metadata": {},
   "source": [
    "## Assumptions\n",
    "Observations in each sample are independent and identically distributed (iid).  \n",
    "Observations in each sample are normally distributed.  \n",
    "Observations in each sample have the same variance. \n",
    "    \n",
    "$H_{0}$: The data is normally distributed.  \n",
    "$H_{1}$: The data is not normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0a292de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_A = np.array([89.8, 89.9, 88.6, 88.7, 89.6, 89.7, 89.2, 89.3])\n",
    "method_B =   np.array([90.0, 90.1, 88.8, 88.9, 89.9, 90.0, 89.0, 89.2])\n",
    "method_C = np.array([91.5, 90.7, 90.3, 90.4, 90.2, 90.3, 90.2, 90.3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2c5e2c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapiro-Wilk Test for Method A: Statistic=0.9030, p-value=0.3076\n",
      "Shapiro-Wilk Test for Method B: Statistic=0.8241, p-value=0.0515\n",
      "Shapiro-Wilk Test for Method C: Statistic=0.6865, p-value=0.0016\n",
      "Method A: Data is normally distributed.\n",
      "Method B: Data is normally distributed.\n",
      "Method C: Data is not normally distributed.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "shapiro_A = shapiro(method_A)\n",
    "shapiro_B = shapiro(method_B)\n",
    "shapiro_C = shapiro(method_C)\n",
    "print(f\"Shapiro-Wilk Test for Method A: Statistic={shapiro_A.statistic:.4f}, p-value={shapiro_A.pvalue:.4f}\")\n",
    "print(f\"Shapiro-Wilk Test for Method B: Statistic={shapiro_B.statistic:.4f}, p-value={shapiro_B.pvalue:.4f}\")\n",
    "print(f\"Shapiro-Wilk Test for Method C: Statistic={shapiro_C.statistic:.4f}, p-value={shapiro_C.pvalue:.4f}\")\n",
    "if shapiro_A.pvalue < 0.05:\n",
    "    print(\"Method A: Data is not normally distributed.\")\n",
    "else:\n",
    "    print(\"Method A: Data is normally distributed.\")\n",
    "if shapiro_B.pvalue < 0.05:\n",
    "    print(\"Method B: Data is not normally distributed.\")\n",
    "else:\n",
    "    print(\"Method B: Data is normally distributed.\")\n",
    "if shapiro_C.pvalue < 0.05:\n",
    "    print(\"Method C: Data is not normally distributed.\")\n",
    "else:\n",
    "    print(\"Method C: Data is normally distributed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ad19116f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levene's Test for Homogeneity of Variances: p-value=0.1953\n",
      "The variances of the samples are the same.\n"
     ]
    }
   ],
   "source": [
    "pvalue_levene = stats.levene(method_A, method_B, method_C).pvalue\n",
    "print(f\"Levene's Test for Homogeneity of Variances: p-value={pvalue_levene:.4f}\")\n",
    "if pvalue_levene < 0.05:\n",
    "    print(\"The variances of the samples are different.\")\n",
    "else:\n",
    "    print(\"The variances of the samples are the same.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a74c6bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.0015\n",
      "Reject null hypothesis\n",
      "89.35 89.49 90.49\n"
     ]
    }
   ],
   "source": [
    "test_stat,p_value = stats.friedmanchisquare(method_A,method_B, method_C)\n",
    "print(\"p value:%.4f\" % p_value)\n",
    "if p_value <0.05:\n",
    "    print(\"Reject null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis\")\n",
    "    \n",
    "print(np.round(np.mean(method_A),2), np.round(np.mean(method_B),2), np.round(np.mean(method_C),2))     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3759e2ea",
   "metadata": {},
   "source": [
    "### **posthoc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eb2b1ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c0386_row0_col0, #T_c0386_row0_col1, #T_c0386_row1_col0, #T_c0386_row1_col1, #T_c0386_row2_col2 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "#T_c0386_row0_col2, #T_c0386_row1_col2, #T_c0386_row2_col0, #T_c0386_row2_col1 {\n",
       "  background-color: violet;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c0386\">\n",
       "  <caption>Pairwise Wilcoxon Signed-Rank Test Results with Holm Correction</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c0386_level0_col0\" class=\"col_heading level0 col0\" >Method A</th>\n",
       "      <th id=\"T_c0386_level0_col1\" class=\"col_heading level0 col1\" >Method B</th>\n",
       "      <th id=\"T_c0386_level0_col2\" class=\"col_heading level0 col2\" >Method C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c0386_level0_row0\" class=\"row_heading level0 row0\" >Method A</th>\n",
       "      <td id=\"T_c0386_row0_col0\" class=\"data row0 col0\" >1.0000</td>\n",
       "      <td id=\"T_c0386_row0_col1\" class=\"data row0 col1\" >0.1094</td>\n",
       "      <td id=\"T_c0386_row0_col2\" class=\"data row0 col2\" >0.0234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c0386_level0_row1\" class=\"row_heading level0 row1\" >Method B</th>\n",
       "      <td id=\"T_c0386_row1_col0\" class=\"data row1 col0\" >0.1094</td>\n",
       "      <td id=\"T_c0386_row1_col1\" class=\"data row1 col1\" >1.0000</td>\n",
       "      <td id=\"T_c0386_row1_col2\" class=\"data row1 col2\" >0.0234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c0386_level0_row2\" class=\"row_heading level0 row2\" >Method C</th>\n",
       "      <td id=\"T_c0386_row2_col0\" class=\"data row2 col0\" >0.0234</td>\n",
       "      <td id=\"T_c0386_row2_col1\" class=\"data row2 col1\" >0.0234</td>\n",
       "      <td id=\"T_c0386_row2_col2\" class=\"data row2 col2\" >1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x24930910140>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([method_A, method_B, method_C]) \n",
    "posthoc_df=sp.posthoc_wilcoxon(data, p_adjust=\"holm\")\n",
    "# posthoc_df = sp.posthoc_nemenyi_friedman(data.T) ## another option for the posthoc test\n",
    "\n",
    "group_names= [\"Method A\", \"Method B\",\"Method C\"]\n",
    "posthoc_df.columns= group_names\n",
    "posthoc_df.index= group_names\n",
    "posthoc_df.style.map(lambda x: \"background-color:violet\" if x<0.05 else \"background-color: lightgreen\", subset=group_names).format(\"{:.4f}\").set_caption(\"Pairwise Wilcoxon Signed-Rank Test Results with Holm Correction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa187ce",
   "metadata": {},
   "source": [
    "Method C outperformed others and achieved better accuracy scores than the others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd33648b",
   "metadata": {},
   "source": [
    "------------\n",
    "\n",
    "## Q8.\n",
    "\n",
    "An analyst of a financial investment company is curious about the relationship between gender and risk appetite. A random sample was taken of 660 customers from the database. The customers in the sample were classified according to their gender and their risk appetite. The result is given in the following table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458743fc",
   "metadata": {},
   "source": [
    "Test the hypothesis that the risk appetite of the customers in this company is independent of their gender. Use α = 0.01.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7e4ce1",
   "metadata": {},
   "source": [
    "$H_{0}$: Gender and risk appetite are independent.   \n",
    "$H_{1}$: Gender and risk appetite are dependent. \n",
    "\n",
    "chi2 test should be used for this question. This test is known as the goodness-of-fit test. It implies that if the observed data are very close to the expected data. The assumption of this test every Ei ≥ 5 (in at least 80% of the cells) which is satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "93e7ad63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected frequencies:\n",
      "  [[ 43.21  24.74  28.23  32.41 101.41]\n",
      " [ 80.79  46.26  52.77  60.59 189.59]]\n",
      "degrees of freedom: 4\n",
      "test stat :7.0942\n",
      "p value:0.1310\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "obs =np.array([[53, 23, 30, 36, 88],[71, 48, 51, 57, 203]])\n",
    "chi2, p, dof, ex = chi2_contingency(obs, correction=False)\n",
    "\n",
    "print(\"expected frequencies:\\n \", np.round(ex,2))\n",
    "print(\"degrees of freedom:\", dof)\n",
    "print(\"test stat :%.4f\" % chi2)\n",
    "print(\"p value:%.4f\" % p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4d50c6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "critical stat:13.2767\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2\n",
    "## calculate critical stat\n",
    "\n",
    "alpha = 0.01\n",
    "df = (5-1)*(2-1)\n",
    "critical_stat = chi2.ppf((1-alpha), df)\n",
    "print(\"critical stat:%.4f\" % critical_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fabaf41",
   "metadata": {},
   "source": [
    "Since p value is larger than α=0.01 ( or calculated statistic=7.14 is smaller than the critical statistic=13.28) >> Fail to Reject H0. At this significance level, it can be concluded that gender and risk appetite are independent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
